Take a look back at some of the most popular TV programs of the mid-1960s — “The Dick Van Dyke Show,” “Bewitched,” even “The Beverly Hillbillies” — and what do you see?

Like today, middle-class Americans typically had washing machines and air-conditioning, telephones and cars. The Internet and video games were not yet invented. But life, over all, did not look that different.

There were TVs and radios in most homes. Millions of people worked in downtown offices and lived in suburbs, connected by multilane highways. Americans’ average life expectancy at birth was 70, only eight years less than it is today.

But flash back 50 years earlier. Then, less than half the population lived in cities. Though Ford Model T’s were starting to roll off the assembly line, Americans typically moved around on horse-drawn buggies on dirt or cobblestone roads. Refrigerators or TVs? Most homes weren’t even wired for electricity. And average life expectancy was only 53.

Americans like to think they live in an era of rapid and unprecedented change, but this kind of comparison — pitting the momentous changes of the mid-20th century against the seemingly more modest progress of our present era — raises a critical question about the nation’s future prosperity.

What does this portend for our well-being over the next half century? Has technological progress slowed for good?

The idea that America’s best days are behind us sits in sharp tension with the high-tech optimism radiating from the offices of the technology start-ups and venture capital firms of Silicon Valley. But it lies at the heart of the current political unrest. And it is about to elbow its way forcefully into the national conversation.

Robert J. Gordon, a professor of economics at Northwestern University who has patiently developed the proposition in a series of research papers over the last few years, has bundled his arguments into an ambitious new book, “The Rise and Fall of American Growth” (Princeton University Press).

The hefty tome, minutely detailed yet dauntingly broad in scope, offers a lively portrayal of the evolution of American living standards since the Civil War. It also adds up to a dispiriting forecast for American prosperity in the decades to come. “This book,” he writes in the introduction, “ends by doubting that the standard of living of today’s youths will double that of their parents, unlike the standard of living of each previous generation of Americans back to the late 19th century.”

Innovation will trundle along at the same pace of the last 40 years, Professor Gordon predicts. Despite the burst of progress of the Internet era, total factor productivity — which captures innovation’s contribution to growth — rose over that period at about one-third the pace of the previous five decades.

That’s hardly the worst part of the story. The labor force will continue to decline, as aging baby boomers leave the work force and women’s labor supply plateaus. And gains in education, an important driver of productivity that expanded sharply in the 20th century, will contribute little.

Moreover, the growing concentration of income means that whatever the growth rate, most of the population will barely share in its fruits. Altogether, Professor Gordon argues, the disposable income of the bottom 99 percent of the population, which has expanded about 2 percent per year since the late 19th century, will expand over the next few decades at a rate little above zero.

Professor Gordon’s take on the future is, of course, not infallible. Economists generally agree that future growth will be slowed by the headwinds of demography, education and income distribution. But the productivity slowdown of recent decades was clearly affected by one-time factors, including a shattering financial crisis. He is on less solid ground forecasting weakness decades into the future.

Economists, in fact, have no trustworthy theory of what produces technological breakthroughs. Joel Mokyr, an economic historian who also teaches at Northwestern, argues there are reasons to expect enormous breakthroughs are in the offing.

Science has piggybacked on technology ever since Galileo used a telescope to develop a new understanding of the heavens. This new science, in turn, led to new technological innovations.

What Professor Gordon fails to account for, Professor Mokyr argues, is that the information technology revolution and other recent developments produced mind-blowing tools and techniques, from gene-sequencing machines to computers that analyze mountains of data at blistering speed. This is creating vast new opportunities for innovation, from health care to materials technology and beyond.

“The tools available to science have been improving at a dazzling rate,” he told me. “I’m not sure how, but the world of technology in 30 to 40 years’ time will be vastly different than it is today.”

Nonetheless, Professor Gordon’s argument is not easy to dismiss. He does not forecast that technological progress will slow to a crawl. His argument, rather, is that the explosion of innovation and prosperity from 1920 through 1970 was a one-time phenomenon. From now on, progress will continue at the more gradual pace of both the last 40 years and the period before 1920.

“There is plenty of room in my forecast for evolutionary change,” he told me. “What is lacking is sharp, discrete change.”

He is not the only economist forecasting slower progress, now that the burst of productivity gains of the late 1990s and early 2000s has waned. “Growth in educational attainment, developed-economy R&D intensity and population are all likely to be slower in the future than in the past,” John G. Fernald of the Federal Reserve Bank of San Francisco and Charles I. Jones of Stanford wrote in a recent article.

Professor Gordon’s view of slowing technological opportunities meshes with other bits of evidence.

Ben S. Bernanke, the former chairman of the Federal Reserve who is now at the Brookings Institution, points out that long-term interest rates have been declining for a very long time. This is in response partly to the accumulation of savings in China and other developing economies, which have been buying Treasury bonds hand over fist. But it also suggests that investors, whether they realize it or not, may agree with Professor Gordon’s proposition.

“People who invest money in the markets are saying the rate of return on capital investments is lower than it was 15 or 30 years ago,” Mr. Bernanke said. “Gordon’s forecast is not without some market reality.”

Other strands of data point in this direction. Business dynamism, measured by the role of new companies in the economy, appears to be waning. The share of employment in companies less than five years old dropped from about 19 percent in 1982 to 11 percent in 2011.

Skepticism is warranted, to be sure. Since the time of Thomas Malthus, eras of depressed expectations like our own have inspired predictions of doom and gloom that were proved wrong once economies turned up a few years down the road.

“For reasons I have never understood, people like to hear that the world is going to hell,” the economic historian Deirdre N. McCloskey of the University of Illinois, Chicago, wrote in an essay about “Capital in the Twenty-First Century,” the blockbuster about income inequality by the French economist Thomas Piketty. “Yet pessimism has consistently been a poor guide to the modern economic world.”

Optimism, though, is also subject to cognitive biases. It’s not just that the income of our optimistic techno-entrepreneurs is growing faster than gross domestic product. A lot of new innovation — the rockets to vacations in orbit, the Apple Watch and Google Glass — also seems custom-designed for them.

“If you are sitting in Silicon Valley, rich and at the frontier of technology,” said Lawrence F. Katz of Harvard, “it is probably true that things are getting better.”

The same can’t always be said for the rest of us.